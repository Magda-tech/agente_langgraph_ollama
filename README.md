# README - Agente LangGraph + Ollama (usando o modelo gemma3)

Este guia explica como configurar e rodar um agente conversacional simples usando Python, LangGraph, Ollama, e o modelo local gemma3. Ideal para quem est√° come√ßando com programa√ß√£o e ambientes virtuais.

## üöÄ Pr√©-requisitos

1. **Baixe e instale o Python 3.10 no seu computador.**
2. **Anaconda Prompt (recomendado)**
3. **Ollama instalado**: https://ollama.com/download
4. **Modelo gemma3 baixado**:
  
## üõ†Ô∏è Como usar

1. Clone o reposit√≥rio para sua m√°quina usando o comando abaixo :
   
git clone https://github.com/Magda-tech/agente_langgraph_ollama.git

2. Crie um ambiente Conda no Anaconda Prompt:
   ```
   conda create -n langgraph_ollama python=3.10 # cria o ambiente
   conda activate langgraph_ollama              # ativa o ambiente
   cd agente_langgraph_ollama                   # entra na pasta onde est√° o arquivo requirements.txt
   pip install -r requirements.txt              # instala os pacotes no ambiente ativo

   ```
   
 3. Inicie o modelo gemma3 (em outro terminal):
    
   ```
  ollama run gemma3
   ```

4. Volte para o terminal no ambiente ativado langgraph_ollama e rode:
   
   ```
   pip install langchain-ollama
    ```
6. Abra o VS Code, use o comando Ctrl+Shift+P (Windows) e selecione Python: Select Interpreter e escolha o interpretador Python do ambiente Conda criado (langgraph_ollama).
 
 Agora voc√™ pode rodar o arquivo Python direto no VS Code usando o bot√£o de execu√ß√£o ou terminal integrado.
 Digite suas perguntas no terminal. Para sair, digite sair.

## üß™ Exemplos para testar

- `Quanto √© 8 * 5?`
- `Onde fica o Brasil?`
- `Explique o que √© LangGraph`

---
# Arquivos principais

agente_langgraph_ollama.py ‚Äî c√≥digo principal do agente

requirements.txt ‚Äî depend√™ncias Python

.gitignore ‚Äî arquivos ignorados no reposit√≥rio

‚úÖ Feito por Magda Monteiro para aprender sobre agentes inteligentes com modelos locais.
